{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc69624-e22e-447e-b2dd-c84b9e30bcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Write Python code and use MapReduct to count occurrences of each word in the first text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd7d99ef-f9d3-4be2-8e5a-14e59f8b87a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the : 135\n",
      "to : 65\n",
      "and : 64\n",
      "his : 60\n",
      "he : 59\n",
      "i : 56\n",
      "you : 56\n",
      "harry : 51\n",
      "of : 50\n",
      "was : 50\n",
      "a : 45\n",
      "s : 41\n",
      "in : 37\n",
      "dudley : 34\n",
      "it : 33\n",
      "on : 32\n",
      "as : 27\n",
      "him : 25\n",
      "t : 25\n",
      "had : 23\n"
     ]
    }
   ],
   "source": [
    "# DOB: 2000-05-15\n",
    "\n",
    "import re\n",
    "\n",
    "# mapper step: turn words into (word, 1) pairs\n",
    "def mapper(text):\n",
    "    words = re.findall(r\"[A-Za-z]+\", text.lower())\n",
    "    pairs = []\n",
    "    for word in words:\n",
    "        pairs.append((word, 1))\n",
    "    return pairs\n",
    "\n",
    "# shuffle step: group counts by word\n",
    "def shuffle(pairs):\n",
    "    grouped = {}\n",
    "    for word, count in pairs:\n",
    "        if word not in grouped:\n",
    "            grouped[word] = []\n",
    "        grouped[word].append(count)\n",
    "    return grouped\n",
    "\n",
    "# reducer step: add up counts for each word\n",
    "def reducer(grouped):\n",
    "    results = {}\n",
    "    for word, counts in grouped.items():\n",
    "        results[word] = sum(counts)\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # read the text file (file1.txt)\n",
    "    with open(r\"C:\\Users\\gopim\\OneDrive\\Desktop\\MapRed\\file1.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # run map, shuffle, reduce\n",
    "    mapped = mapper(text)\n",
    "    grouped = shuffle(mapped)\n",
    "    reduced = reducer(grouped)\n",
    "\n",
    "    # sort words by count (highest first)\n",
    "    sorted_words = sorted(reduced.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "    # print top 20 words\n",
    "    for word, count in sorted_words[:20]:\n",
    "        print(word, \":\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ba367-2443-4633-90eb-7eadcf8fbe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. From the second text file (file2.txt), write Python code and use MapReduct to count how many times non-English words\n",
    "(names, places, spells etc.) were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "930e2274-c7d1-4529-97f0-d4dd20ab789a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 30 non-English-like words:\n",
      "kreacher : 35\n",
      "weasley : 14\n",
      "voldemort : 6\n",
      "lestrange : 3\n",
      "mudblood : 3\n",
      "muggle : 3\n",
      "tonks : 3\n",
      "azkaban : 2\n",
      "purebloods : 2\n",
      "snackboxes : 2\n",
      "aboutit : 1\n",
      "auror : 1\n",
      "borns : 1\n",
      "crookshanks : 1\n",
      "doxying : 1\n",
      "elladora : 1\n",
      "hearhim : 1\n",
      "hogwarts : 1\n",
      "malfoy : 1\n",
      "malfoys : 1\n",
      "meliflua : 1\n",
      "mudbloods : 1\n",
      "narcissa : 1\n",
      "narcissablack : 1\n",
      "ncient : 1\n",
      "nigellus : 1\n",
      "oble : 1\n",
      "ofsteam : 1\n",
      "onvoldemort : 1\n",
      "oujours : 1\n"
     ]
    }
   ],
   "source": [
    "# DOB: 2000-05-15\n",
    "\n",
    "import re\n",
    "\n",
    "# loading english words from dictionary file\n",
    "english = set()\n",
    "with open(r\"C:\\Users\\gopim\\OneDrive\\Desktop\\MapRed\\words.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    for line in f:\n",
    "        w = line.strip().lower()\n",
    "        if len(w) >= 3:\n",
    "            english.add(w)\n",
    "\n",
    "# stoplist for contraction leftovers\n",
    "stoplist = {\"ll\",\"ve\",\"re\",\"im\",\"dont\",\"cant\",\"didnt\",\"wasnt\",\"isnt\",\"arent\",\n",
    "            \"youre\",\"theyre\",\"ive\",\"id\",\"weve\",\"youve\",\"hed\",\"shed\",\"wed\"}\n",
    "\n",
    "# read the input text\n",
    "with open(r\"C:\\Users\\gopim\\OneDrive\\Desktop\\MapRed\\file2.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# mapper step\n",
    "pairs = []\n",
    "words = re.findall(r\"[A-Za-z]+\", text.lower())\n",
    "for word in words:\n",
    "    if len(word) <= 2:\n",
    "        continue\n",
    "    if word in english:\n",
    "        continue\n",
    "    if word in stoplist:\n",
    "        continue\n",
    "    pairs.append((word, 1))\n",
    "\n",
    "# shuffle step\n",
    "grouped = {}\n",
    "for word, count in pairs:\n",
    "    if word not in grouped:\n",
    "        grouped[word] = []\n",
    "    grouped[word].append(count)\n",
    "\n",
    "# reducer step\n",
    "reduced = {}\n",
    "for word, counts in grouped.items():\n",
    "    reduced[word] = sum(counts)\n",
    "\n",
    "# sort results\n",
    "sorted_words = sorted(reduced.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "# print top 30 non-english words\n",
    "print(\"Top 30 non-English-like words:\")\n",
    "for word, count in sorted_words[:30]:\n",
    "    print(word, \":\", count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
